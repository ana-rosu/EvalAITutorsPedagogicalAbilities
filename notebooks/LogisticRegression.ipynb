{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        data = [item for item in data]\n",
    "    return data\n",
    "\n",
    "def create_df(data):\n",
    "    rows = []\n",
    "    for conv in data:\n",
    "        conv_id = conv[\"conversation_id\"]\n",
    "        history = conv[\"conversation_history\"]\n",
    "        \n",
    "        for model_name, response_data in conv[\"tutor_responses\"].items():\n",
    "            row = {\n",
    "                \"conversation_id\": conv_id,\n",
    "                \"conversation_history\": history,\n",
    "                \"model\": model_name,\n",
    "                \"response\": response_data[\"response\"],\n",
    "                \"mistake_identification\": response_data[\"annotation\"][\"Mistake_Identification\"],\n",
    "                \"mistake_location\": response_data[\"annotation\"][\"Mistake_Location\"],\n",
    "                \"providing_guidance\": response_data[\"annotation\"][\"Providing_Guidance\"],\n",
    "                \"actionability\": response_data[\"annotation\"][\"Actionability\"]\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(df, column_name):\n",
    "    mapping = {\"No\": 0, \"To some extent\": 1, \"Yes\": 2}\n",
    "    return df[column_name].map(mapping)\n",
    "\n",
    "def tfidf_vectorize(X_train, X_val):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_val_tfidf = vectorizer.transform(X_val)\n",
    "    return X_train_tfidf, X_val_tfidf, vectorizer\n",
    "\n",
    "def get_class_weights(y_train):\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    return class_weight_dict\n",
    "\n",
    "def train_and_eval(X, y, k, class_weight=None):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_reports = []\n",
    "    for _, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        X_train_tfidf, X_val_tfidf, vectorizer = tfidf_vectorize(X_train, X_val)\n",
    "        if class_weight is not None:\n",
    "            class_weight_dict = get_class_weights(y)\n",
    "        model = LogisticRegression(class_weight=class_weight_dict, max_iter=1000)\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_val_tfidf)\n",
    "        report = classification_report(y_val, y_pred, output_dict=True)\n",
    "        fold_reports.append(report)\n",
    "    return model, vectorizer, fold_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('../data/mrbench_v3_devset.json')\n",
    "df = create_df(data)\n",
    "metrics = ['mistake_identification', 'mistake_location', 'providing_guidance', 'actionability']\n",
    "\n",
    "df[\"last_student_utterance\"] = df[\"conversation_history\"].apply(lambda x: x.split(\"\\n\")[-1].replace(\"Student: \", \"\"))\n",
    "df[\"input_text_1\"] = df[\"response\"] # macro accuracy 0.84 macro f1 0.64 with vectorizer bigrams (before i had 0.80, 0.60) - on 5 folds\n",
    "df[\"input_text_2\"] = df[\"last_student_utterance\"] + \" [SEP] \" + df[\"response\"] # macro accuracy 0.79 macro f1 0.62 (test train 0.8/0.2)\n",
    "df[\"input_text_3\"] = df[\"conversation_history\"] + \" [SEP] \" + df[\"response\"] # macro accuracy 0.55 macro f1 0.41 (test train 0.8/0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_report(fold_reports):\n",
    "    avg_report = {}\n",
    "    for fold_report in fold_reports:  # Iterate through folds\n",
    "        for key in fold_report.keys(): # Iterate through keys (0, 1, 2, accuracy, macro avg, weighted avg)\n",
    "            if isinstance(fold_report[key], dict):  # Handle per-class metrics\n",
    "                avg_report[key] = {}\n",
    "                for subkey in fold_report[key]: # Iterate through subkeys (precision, recall, f1-score, support)\n",
    "                    avg_report[key][subkey] = np.mean([report[key][subkey] for report in fold_reports])\n",
    "            else: # accuracy \n",
    "                avg_report[key] = np.mean([report[key] for report in fold_reports])\n",
    "\n",
    "    return avg_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression + TF-IDF + class weights\n",
    "def get_results(input_data, class_weight=True):\n",
    "    results = {}\n",
    "    for metric in metrics:\n",
    "        print(f\"\\nTraining model for: {metric}\")\n",
    "        df[\"labels\"] = encode_labels(df, metric)\n",
    "        model, vectorizer, fold_reports = train_and_eval(input_data, df[\"labels\"], k=5, class_weight=class_weight)\n",
    "        avg_report = get_avg_report(fold_reports)\n",
    "        results[metric] = {\n",
    "            \"model\": model,\n",
    "            \"vectorizer\": vectorizer\n",
    "        }\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(avg_report)\n",
    "        print(f'Macro accuracy: {avg_report[\"accuracy\"]} Macro F1: {avg_report[\"macro avg\"][\"f1-score\"]}')\n",
    "        print(\"----------------------------------------------------\")\n",
    "    return results\n",
    "\n",
    "import joblib\n",
    "def save_trained_models_and_vectorizers_for_inference(results, folder):\n",
    "    for metric, data in results.items():\n",
    "        model = data[\"model\"]\n",
    "        vectorizer = data[\"vectorizer\"]\n",
    "        joblib.dump(model, f\"../models/{folder}/{metric}_model.pkl\")\n",
    "        joblib.dump(vectorizer, f\"../models/{folder}/{metric}_vectorizer.pkl\")\n",
    "\n",
    "# bigrams results\n",
    "# Training model for: mistake_identification\n",
    "# Macro accuracy: 0.8485434995112415 Macro F1: 0.6438575934024939\n",
    "# Training model for: mistake_location\n",
    "# Macro accuracy: 0.6890029325513196 Macro F1: 0.5596451814761345\n",
    "# Training model for: providing_guidance\n",
    "# Macro accuracy: 0.6385272075594657 Macro F1: 0.5787090520169101\n",
    "# Metric: actionability\n",
    "# Macro accuracy: 0.6478258390355165 Macro F1: 0.5748426701105898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for: mistake_identification\n",
      "Metric: mistake_identification\n",
      "{'0': {'precision': 0.8370572493215352, 'recall': 0.6702702702702703, 'f1-score': 0.7426457459251125, 'support': 74.0}, '1': {'precision': 0.35665041576219114, 'recall': 0.2073949579831933, 'f1-score': 0.2593421951912518, 'support': 34.8}, '2': {'precision': 0.8869579483969614, 'recall': 0.9534160742258104, 'f1-score': 0.9189436707782095, 'support': 386.4}, 'accuracy': 0.858646953405018, 'macro avg': {'precision': 0.6935552044935627, 'recall': 0.6103604341597579, 'f1-score': 0.6403105372981912, 'support': 495.2}, 'weighted avg': {'precision': 0.8422397398037942, 'recall': 0.858646953405018, 'f1-score': 0.8462253367735446, 'support': 495.2}}\n",
      "Macro accuracy: 0.858646953405018 Macro F1: 0.6403105372981912\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: mistake_location\n",
      "Metric: mistake_location\n",
      "{'0': {'precision': 0.6870107957673521, 'recall': 0.5960504284447946, 'f1-score': 0.6377282005201393, 'support': 142.6}, '1': {'precision': 0.23249147219863553, 'recall': 0.23181818181818184, 'f1-score': 0.22967841004997352, 'support': 44.0}, '2': {'precision': 0.7728135133359157, 'recall': 0.8152755011978312, 'f1-score': 0.7933954976573774, 'support': 308.6}, 'accuracy': 0.7003071032909742, 'macro avg': {'precision': 0.5641052604339677, 'recall': 0.5477147038202692, 'f1-score': 0.5536007027424967, 'support': 495.2}, 'weighted avg': {'precision': 0.7000924711465663, 'recall': 0.7003071032909742, 'f1-score': 0.6984795143339142, 'support': 495.2}}\n",
      "Macro accuracy: 0.7003071032909742 Macro F1: 0.5536007027424967\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: providing_guidance\n",
      "Metric: providing_guidance\n",
      "{'0': {'precision': 0.6772255892255892, 'recall': 0.5088340319826115, 'f1-score': 0.5799852537229138, 'support': 113.2}, '1': {'precision': 0.3879780369751428, 'recall': 0.40550495049504953, 'f1-score': 0.3956791331194084, 'support': 100.6}, '2': {'precision': 0.7165118015546844, 'recall': 0.7761237727467757, 'f1-score': 0.7447147286923135, 'support': 281.4}, 'accuracy': 0.6397368849788204, 'macro avg': {'precision': 0.5939051425851388, 'recall': 0.5634875850748122, 'f1-score': 0.5734597051782119, 'support': 495.2}, 'weighted avg': {'precision': 0.6408167296868408, 'recall': 0.6397368849788204, 'f1-score': 0.6361629822052726, 'support': 495.2}}\n",
      "Macro accuracy: 0.6397368849788204 Macro F1: 0.5734597051782119\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: actionability\n",
      "Metric: actionability\n",
      "{'0': {'precision': 0.7308423881030487, 'recall': 0.6324056603773585, 'f1-score': 0.6778574783544478, 'support': 159.4}, '1': {'precision': 0.31940801457194895, 'recall': 0.30903369122547203, 'f1-score': 0.3121104638173293, 'support': 73.8}, '2': {'precision': 0.6990357866960226, 'recall': 0.7633587786259542, 'f1-score': 0.7295168042813984, 'support': 262.0}, 'accuracy': 0.6534856630824373, 'macro avg': {'precision': 0.5830953964570067, 'recall': 0.5682660434095949, 'f1-score': 0.5731615821510585, 'support': 495.2}, 'weighted avg': {'precision': 0.6526786844955231, 'recall': 0.6534856630824373, 'f1-score': 0.6506667986528665, 'support': 495.2}}\n",
      "Macro accuracy: 0.6534856630824373 Macro F1: 0.5731615821510585\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results1 = get_results(df[\"input_text_1\"])\n",
    "# results2 = get_results(df[\"input_text_2\"])\n",
    "# results3 = get_results(df[\"input_text_3\"])\n",
    "# save_trained_models_and_vectorizers_for_inference(results1, 'logreg_tfidf_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for: mistake_identification\n",
      "Metric: mistake_identification\n",
      "{'0': {'precision': np.float64(0.7233545794541258), 'recall': np.float64(0.6864864864864864), 'f1-score': np.float64(0.7030764075132526), 'support': np.float64(74.0)}, '1': {'precision': np.float64(0.24362669494248443), 'recall': np.float64(0.2989915966386555), 'f1-score': np.float64(0.2665014115557017), 'support': np.float64(34.8)}, '2': {'precision': np.float64(0.9027660099980569), 'recall': np.float64(0.8907873773279243), 'f1-score': np.float64(0.896546647011939), 'support': np.float64(386.4)}, 'accuracy': np.float64(0.8186567285760834), 'macro avg': {'precision': np.float64(0.6232490947982224), 'recall': np.float64(0.6254218201510221), 'f1-score': np.float64(0.6220414886936311), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.8296538405247411), 'recall': np.float64(0.8186567285760834), 'f1-score': np.float64(0.8233668102962064), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.8186567285760834 Macro F1: 0.6220414886936311\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: mistake_location\n",
      "Metric: mistake_location\n",
      "{'0': {'precision': np.float64(0.6361047188926512), 'recall': np.float64(0.6171180931744312), 'f1-score': np.float64(0.6256519760581329), 'support': np.float64(142.6)}, '1': {'precision': np.float64(0.2340351123227309), 'recall': np.float64(0.35454545454545455), 'f1-score': np.float64(0.2789263530487099), 'support': np.float64(44.0)}, '2': {'precision': np.float64(0.7955711250575656), 'recall': np.float64(0.7452843273231622), 'f1-score': np.float64(0.7693099747364652), 'support': np.float64(308.6)}, 'accuracy': np.float64(0.6736591723688499), 'macro avg': {'precision': np.float64(0.555236985424316), 'recall': np.float64(0.5723159583476827), 'f1-score': np.float64(0.5579627679477694), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.6997724099922075), 'recall': np.float64(0.6736591723688499), 'f1-score': np.float64(0.6843762733847711), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.6736591723688499 Macro F1: 0.5579627679477694\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: providing_guidance\n",
      "Metric: providing_guidance\n",
      "{'0': {'precision': np.float64(0.5902379109551364), 'recall': np.float64(0.5494333178077937), 'f1-score': np.float64(0.5687397347581198), 'support': np.float64(113.2)}, '1': {'precision': np.float64(0.38437574865982577), 'recall': np.float64(0.4689108910891089), 'f1-score': np.float64(0.42137299457970234), 'support': np.float64(100.6)}, '2': {'precision': np.float64(0.7275184880113743), 'recall': np.float64(0.6901113046111911), 'f1-score': np.float64(0.7079252529830047), 'support': np.float64(281.4)}, 'accuracy': np.float64(0.6130856956663409), 'macro avg': {'precision': np.float64(0.567377382542112), 'recall': np.float64(0.5694851711693646), 'f1-score': np.float64(0.566012660773609), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.6264444714392223), 'recall': np.float64(0.6130856956663409), 'f1-score': np.float64(0.6179352371114695), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.6130856956663409 Macro F1: 0.566012660773609\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: actionability\n",
      "Metric: actionability\n",
      "{'0': {'precision': np.float64(0.6909647631222695), 'recall': np.float64(0.6537106918238993), 'f1-score': np.float64(0.671602151072878), 'support': np.float64(159.4)}, '1': {'precision': np.float64(0.2940386828361512), 'recall': np.float64(0.3741577193631988), 'f1-score': np.float64(0.32806551544845164), 'support': np.float64(73.8)}, '2': {'precision': np.float64(0.7157357235094155), 'recall': np.float64(0.683969465648855), 'f1-score': np.float64(0.6987226708010557), 'support': np.float64(262.0)}, 'accuracy': np.float64(0.6280311176278918), 'macro avg': {'precision': np.float64(0.5669130564892788), 'recall': np.float64(0.5706126256119843), 'f1-score': np.float64(0.5661301124407951), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.6449176782394413), 'recall': np.float64(0.6280311176278918), 'f1-score': np.float64(0.6347438676242205), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.6280311176278918 Macro F1: 0.5661301124407951\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + TF-IDF + SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "def get_results_smote(input_data):\n",
    "    results = {}\n",
    "    for metric in metrics:\n",
    "        print(f\"\\nTraining model for: {metric}\")\n",
    "        df[\"labels\"] = encode_labels(df, metric)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_reports = []\n",
    "        X = input_data\n",
    "        y = df[\"labels\"]\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            X_train_tfidf, X_val_tfidf, vectorizer = tfidf_vectorize(X_train, X_val)\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "            model = LogisticRegression(max_iter=1000)\n",
    "            model.fit(X_train_resampled, y_train_resampled)\n",
    "            y_pred = model.predict(X_val_tfidf)\n",
    "            report = classification_report(y_val, y_pred, output_dict=True)\n",
    "            fold_reports.append(report)\n",
    "\n",
    "        avg_report = get_avg_report(fold_reports)\n",
    "        results[metric] = {\n",
    "            \"model\": model,\n",
    "            \"vectorizer\": vectorizer\n",
    "        }\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(avg_report)\n",
    "        print(f'Macro accuracy: {avg_report[\"accuracy\"]} Macro F1: {avg_report[\"macro avg\"][\"f1-score\"]}')\n",
    "        print(\"----------------------------------------------------\")\n",
    "    return results\n",
    "\n",
    "results_smote1 = get_results_smote(df[\"input_text_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for: mistake_identification\n",
      "Metric: mistake_identification\n",
      "{'0': {'precision': np.float64(0.7939232409381662), 'recall': np.float64(0.6756756756756757), 'f1-score': np.float64(0.7285221366878525), 'support': np.float64(74.0)}, '1': {'precision': np.float64(0.3292307692307692), 'recall': np.float64(0.27630252100840336), 'f1-score': np.float64(0.2972179646065013), 'support': np.float64(34.8)}, '2': {'precision': np.float64(0.896370965510871), 'recall': np.float64(0.9342598171131729), 'f1-score': np.float64(0.9148493877750459), 'support': np.float64(386.4)}, 'accuracy': np.float64(0.8493515803193222), 'macro avg': {'precision': np.float64(0.6731749918932689), 'recall': np.float64(0.628746004599084), 'f1-score': np.float64(0.6468631630231332), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.8412165577861371), 'recall': np.float64(0.8493515803193222), 'f1-score': np.float64(0.8435916550821816), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.8493515803193222 Macro F1: 0.6468631630231332\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: mistake_location\n",
      "Metric: mistake_location\n",
      "{'0': {'precision': np.float64(0.669630884511977), 'recall': np.float64(0.6044617354476509), 'f1-score': np.float64(0.635120926165531), 'support': np.float64(142.6)}, '1': {'precision': np.float64(0.24594911864116717), 'recall': np.float64(0.309090909090909), 'f1-score': np.float64(0.27201099035193227), 'support': np.float64(44.0)}, '2': {'precision': np.float64(0.7854635468781745), 'recall': np.float64(0.7900012608750473), 'f1-score': np.float64(0.7876523043108346), 'support': np.float64(308.6)}, 'accuracy': np.float64(0.6938440860215053), 'macro avg': {'precision': np.float64(0.5670145166771062), 'recall': np.float64(0.5678513018045357), 'f1-score': np.float64(0.5649280736094326), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.7041687437258272), 'recall': np.float64(0.6938440860215053), 'f1-score': np.float64(0.6979118282809748), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.6938440860215053 Macro F1: 0.5649280736094326\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: providing_guidance\n",
      "Metric: providing_guidance\n",
      "{'0': {'precision': np.float64(0.6502991924185892), 'recall': np.float64(0.5300574444961962), 'f1-score': np.float64(0.5826087961845936), 'support': np.float64(113.2)}, '1': {'precision': np.float64(0.3962144195552609), 'recall': np.float64(0.43738613861386133), 'f1-score': np.float64(0.41545550539747006), 'support': np.float64(100.6)}, '2': {'precision': np.float64(0.7218249907310011), 'recall': np.float64(0.7469700411397995), 'f1-score': np.float64(0.7338494202509687), 'support': np.float64(281.4)}, 'accuracy': np.float64(0.6344843597262952), 'macro avg': {'precision': np.float64(0.589446200901617), 'recall': np.float64(0.5714712080832858), 'f1-score': np.float64(0.5773045739443441), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.639350041550844), 'recall': np.float64(0.6344843597262952), 'f1-score': np.float64(0.6345970398816666), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.6344843597262952 Macro F1: 0.5773045739443441\n",
      "----------------------------------------------------\n",
      "\n",
      "Training model for: actionability\n",
      "Metric: actionability\n",
      "{'0': {'precision': np.float64(0.7156136907091067), 'recall': np.float64(0.6549449685534591), 'f1-score': np.float64(0.6835711482065283), 'support': np.float64(159.4)}, '1': {'precision': np.float64(0.307593247825446), 'recall': np.float64(0.3335431321732692), 'f1-score': np.float64(0.3182447513432856), 'support': np.float64(73.8)}, '2': {'precision': np.float64(0.7195002056093671), 'recall': np.float64(0.7404580152671756), 'f1-score': np.float64(0.7293505066807507), 'support': np.float64(262.0)}, 'accuracy': np.float64(0.6522719126751384), 'macro avg': {'precision': np.float64(0.5809023813813066), 'recall': np.float64(0.5763153719979679), 'f1-score': np.float64(0.5770554687435216), 'support': np.float64(495.2)}, 'weighted avg': {'precision': np.float64(0.6568388418205418), 'recall': np.float64(0.6522719126751384), 'f1-score': np.float64(0.653327576956171), 'support': np.float64(495.2)}}\n",
      "Macro accuracy: 0.6522719126751384 Macro F1: 0.5770554687435216\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + TF-IDF + sentence piece tokenization\n",
    "import sentencepiece as spm\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "sp_model_path = hf_hub_download(repo_id=\"google/t5-v1_1-base\", filename=\"spiece.model\")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(sp_model_path)\n",
    "\n",
    "df[\"tokenized_response\"] = df[\"response\"].apply(lambda x: \" \".join(sp.EncodeAsPieces(x)))\n",
    "\n",
    "results_sp1 = get_results(df[\"tokenized_response\"], class_weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ▁Great , ▁you ' ve ▁correctly ▁identified ▁the...\n",
       "1    ▁Now ▁that ▁we ▁know ▁the ▁cost ▁of ▁1 ▁ pound...\n",
       "2    ▁You ' re ▁close , ▁but ▁I ▁notice ▁that ▁you ...\n",
       "3    ▁That ' s ▁correct . ▁So , ▁ if ▁1 ▁ pound ▁of...\n",
       "4    ▁It ▁seems ▁like ▁you ' ve ▁calculated ▁the ▁c...\n",
       "Name: tokenized_response, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokenized_response\"].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
